{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "import sys\n",
    "sys.path.append('/workspace/external-libraries/')\n",
    "\n",
    "import jieba\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.misc import imread,imresize\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from random import seed, choice, sample\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_data(data_root,filename):  \n",
    "    entity = {}\n",
    "    sents = []\n",
    "    sents_tokenize = []\n",
    "    with open(os.path.join(data_root,filename),'r') as f:\n",
    "        data = json.load(f)\n",
    "    for data_part in data['response']['annotations']:\n",
    "        if len(data_part['attributes']) > 5:\n",
    "            seg_list = jieba.cut(data_part['attributes'].strip().replace(u'。',''),cut_all = False)\n",
    "            sents_tokenize.append(list(seg_list))\n",
    "            sents.append(data_part['attributes'])\n",
    "    img_name = annotation.split('_')[0]\n",
    "    if sents != []:\n",
    "        entity['image_name'] = img_name\n",
    "        entity['sents'] = sents\n",
    "        entity['sents_token'] = sents_tokenize\n",
    "        return entity\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulid_vocab(imgs):\n",
    "    param = {}\n",
    "    counts = {}\n",
    "    # bulid_vocab\n",
    "    for img in imgs:\n",
    "        #print(img['sents_token'])\n",
    "        for sent in img['sents_token']:\n",
    "            for w in sent:\n",
    "                counts[w] = counts.get(w,0) + 1\n",
    "                \n",
    "    cw = sorted([(count,w) for w,count in counts.items()],reverse=True)               \n",
    "    print('top words and their counts:')\n",
    "    print('\\n'.join(map(str,cw[:100])))\n",
    "    total_words = sum(counts.values())           \n",
    "    print('total words:', total_words)\n",
    "  \n",
    "    bad_words = [w for w,n in counts.items() if n <= 1]\n",
    "    vocab = [w for w,n in counts.items() if n > 1]\n",
    "    bad_count = sum(counts[w] for w in bad_words)\n",
    "    print('number of bad words: %d/%d = %.2f%%' % (len(bad_words), len(counts), len(bad_words)*100.0/len(counts)))\n",
    "    print('number of words in vocab would be %d' % (len(vocab), ))\n",
    "    print('number of UNKs: %d/%d = %.2f%%' % (bad_count, total_words, bad_count*100.0/total_words))\n",
    "    \n",
    "    sent_lengths = {}\n",
    "    for img in imgs:\n",
    "        for sent in img['sents_token']:\n",
    "            nw = len(sent)\n",
    "            sent_lengths[nw] = sent_lengths.get(nw,0) +1\n",
    "    max_len = max(sent_lengths.keys())\n",
    "    print('max length sentence in raw data: ', max_len)\n",
    "    print('sentence length distribution (count, number of words):')\n",
    "    sum_len = sum(sent_lengths.values())\n",
    "    for i in range(max_len+1):\n",
    "        print('%2d: %10d   %f%%' % (i, sent_lengths.get(i,0), sent_lengths.get(i,0)*100.0/sum_len))\n",
    "    param['max_length'] = max_len\n",
    "    \n",
    "       \n",
    "    vocab.append(u'<unk>')\n",
    "    vocab.append(u'<start>')\n",
    "    vocab.append(u'<end>')\n",
    "    vocab.insert(0,u'<pad>')\n",
    "    \n",
    "    #print(vocab)\n",
    "    for img in imgs:\n",
    "        img['final_captions'] = []\n",
    "        for sent in img['sents_token']:\n",
    "            caption = [w if counts.get(w,0) > 1 else u'UNK' for w in sent]\n",
    "            caption.append(u'<end>')\n",
    "            caption.insert(0,u'<start>')\n",
    "            img['final_captions'].append(caption)\n",
    "    return vocab,param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_files(imgs,split, params, word_map,image_root):\n",
    "    output_folder = './process_data_3/'\n",
    "    max_len = param['max_length'] + 2 \n",
    "    image_name_data = os.listdir(image_root)\n",
    "    with h5py.File(os.path.join(output_folder,'{}_IMAGE.hdf5'.format(split)),'a') as h:\n",
    "        h.attrs['captions_per_image']  = 2\n",
    "        images = h.create_dataset('images',(len(imgs),3,256,256), dtype='uint8')\n",
    "        print('\\nReading images and captions, storing to file...\\n\"')\n",
    "        enc_captions = []\n",
    "        caplens = []\n",
    "\n",
    "        for i, img in enumerate(tqdm(imgs)):\n",
    "            if len(img['final_captions']) < 2:\n",
    "                print(img['image_path'])\n",
    "                captions = img['final_captions'] + [choice(img['final_captions']) for _ in range(2 - len(img['final_captions']))]\n",
    "            else:\n",
    "                captions = sample(img['final_captions'], k=2)\n",
    "\n",
    "            # Sanity check\n",
    "            assert len(captions) == 2\n",
    "            #read image\n",
    "            for image_name in image_name_data:\n",
    "                #print(img['image_path'].split('/')[-1], image_name.split('.')[0])\n",
    "                if img['image_path'].split('/')[-1] == image_name.split('.')[0]:\n",
    "                    img_path = img['image_path'] +'.'+ image_name.split('.')[-1]\n",
    "            #print(img_path)\n",
    "            IMG = np.asarray(Image.open(img_path))\n",
    "            \n",
    "            if len(IMG.shape) == 2:\n",
    "                IMG = IMG[:, :, np.newaxis]\n",
    "                IMG = np.concatenate([IMG, IMG, IMG], axis=2)\n",
    "            \n",
    "            if IMG.shape[-1] == 4:\n",
    "                #print(IMG.shape)\n",
    "                IMG = Image.open(img_path).convert(\"RGB\") \n",
    "           \n",
    "            IMG = imresize(IMG, (256, 256))\n",
    "            IMG = IMG.transpose(2, 0, 1)\n",
    "            assert IMG.shape == (3, 256, 256)\n",
    "            assert np.max(IMG) <= 255\n",
    "            \n",
    "            images[i] = IMG\n",
    "            \n",
    "            #encode caption\n",
    "            for sent in captions:\n",
    "                # word --> word_map['word'] = 1, [1,2,3,4,5] + [0,0,0] \n",
    "                enc_c = [word_map.get(word, word_map['<unk>']) for word in sent] + [word_map['<pad>']] * (max_len - len(sent))\n",
    "                # Find caption lengths\n",
    "                c_len = len(sent)\n",
    "                \n",
    "                enc_captions.append(enc_c)\n",
    "                caplens.append(c_len)\n",
    "        # Sanity check\n",
    "        print(images.shape[0])\n",
    "        print(len(enc_captions), len(caplens))\n",
    "        assert images.shape[0] * 2 == len(enc_captions) == len(caplens)\n",
    "\n",
    "        # Save encoded captions and their lengths to JSON files\n",
    "        with open(os.path.join(output_folder,  '{}_CAPTIONS'.format(split) + '.json'), 'w') as j:\n",
    "            json.dump(enc_captions, j)\n",
    "\n",
    "        with open(os.path.join(output_folder,  '{}_CAPLENS'.format(split) + '.json'), 'w') as j:\n",
    "            json.dump(caplens, j)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['img_rgb','img2','img3']\n",
    "['img_an','img2_an',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file_list = ['./raw_data/新闻描述二期第一批数据/','./raw_data/新闻描述二期第二批数据/']\n",
    "image_root = './raw_data/images_all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./raw_data/新闻描述二期第一批数据/MBM0W5J4M8XP_cm新闻标注二期—游行.txt',\n",
       " './raw_data/新闻描述二期第一批数据/V2X4HARUIC28_cm新闻标注二期—火灾.txt',\n",
       " './raw_data/新闻描述二期第一批数据/W60JBBZY0433_cm新闻标注二期—地震.txt',\n",
       " './raw_data/新闻描述二期第一批数据/7CBDH771T2XH_cm新闻标注二期—空难.txt',\n",
       " './raw_data/新闻描述二期第一批数据/NY5SRX7Y3THH_cm新闻标注二期—暴乱.txt',\n",
       " './raw_data/新闻描述二期第二批数据/TV5LJFQ99YDV_cm新闻标注二期—火灾2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/PY4KBCL7GIWI_cm新闻标注二期—交通事故2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/11XT4VZXXG4I_cm新闻标注二期—洪水2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/ENEA042DXMPS_cm新闻标注二期—暴乱2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/11LL6SPDHRZP_cm新闻标注二期—坍塌2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/FNOTA94NT9TZ_cm新闻标注二期—矿难2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/2I4X0LCU0507_cm新闻标注二期—游行2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/JVLA5FM8MZMG_cm新闻标注二期—海啸2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/RYZNDDUE4RIZ_cm新闻标注二期—泥石流2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/PNBZDL3U82TJ_cm新闻标注二期—空难2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/G5LXGRCH8TGX_cm新闻标注二期—爆炸2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/40YRCTD7WHVD_cm新闻标注二期—山体滑坡2.txt',\n",
       " './raw_data/新闻描述二期第二批数据/KFW9XXH57QQH_cm新闻标注二期—龙卷风2.txt']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_all = []\n",
    "for i in annotation_file_list:\n",
    "    annotation_file = [os.path.join(i,file) for file in os.listdir(i) if file[-4:] == '.txt']\n",
    "    #print(annotation_file)\n",
    "    an_all.extend(annotation_file)\n",
    "an_all    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10201"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构造数据集\n",
    "data_annotations = []\n",
    "for files in an_all:\n",
    "    for annotation in os.listdir(files):\n",
    "        #print(os.path.join(files,annotation))\n",
    "        #print(files)\n",
    "        entity = bulid_data(files,annotation)\n",
    "        if entity:\n",
    "            data_annotations.append(entity)\n",
    "len(data_annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['我'，‘是’，‘下’，‘x’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocab is 3769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8160 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:37: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  0%|          | 2/8160 [00:00<06:51, 19.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading images and captions, storing to file...\n",
      "\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 6664/8160 [03:45<00:36, 40.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/images_all/139169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 7031/8160 [03:55<00:23, 49.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/images_all/117395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8160/8160 [04:23<00:00, 31.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8160\n",
      "16320 16320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/2041 [00:00<01:01, 33.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading images and captions, storing to file...\n",
      "\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1479/2041 [00:38<00:11, 50.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/images_all/139060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1696/2041 [00:42<00:07, 48.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./raw_data/images_all/111227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2041/2041 [00:50<00:00, 40.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2041\n",
      "4082 4082\n"
     ]
    }
   ],
   "source": [
    "# 构造单词表        \n",
    "vocab,param = bulid_vocab(data_annotations)\n",
    "# 单词索引表\n",
    "itow = {i : w for i,w in enumerate(vocab)} # a 1-indexed vocab translation table\n",
    "wtoi = {w:i  for i,w in enumerate(vocab)} # inverse table\n",
    "# 保存单词表\n",
    "with open('./process_data_3/word_map.json','w') as f:\n",
    "    json.dump(wtoi,f)\n",
    "\n",
    "for img in data_annotations:\n",
    "    img['image_path'] = image_root +'/'+ img['image_name']\n",
    "\n",
    "train_data = data_annotations[:int(0.8*len(data_annotations))]\n",
    "val_data = data_annotations[int(0.8*len(data_annotations)):]\n",
    "#输出网络输入文件：编码caption\n",
    "create_input_files(train_data,'train',param, wtoi,image_root)\n",
    "create_input_files(val_data, 'val', param, wtoi,image_root) \n",
    "#保存data_annotations\n",
    "with open('./process_data_3/data_annotations.json','w') as f:\n",
    "    json.dump(data_annotations,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top words and their counts:\n",
      "(28920, '，')\n",
      "(14971, '发生')\n",
      "(14747, '某地')\n",
      "(8760, '现场')\n",
      "(6183, '在')\n",
      "(5914, '救援')\n",
      "(5482, '的')\n",
      "(3718, '正在')\n",
      "(3510, '某')\n",
      "(3088, '火灾')\n",
      "(3027, '人员')\n",
      "(2958, '群众')\n",
      "(2952, '坍塌')\n",
      "(2342, '地震')\n",
      "(2317, '被')\n",
      "(2284, '地区')\n",
      "(2260, '游行')\n",
      "(2127, '房屋')\n",
      "(2023, '上')\n",
      "(1866, '消防员')\n",
      "(1862, '汽车')\n",
      "(1844, '严重')\n",
      "(1811, '事故')\n",
      "(1782, '进行')\n",
      "(1728, '暴乱')\n",
      "(1623, '滑坡')\n",
      "(1594, '山体')\n",
      "(1509, '事故现场')\n",
      "(1495, '大量')\n",
      "(1468, '交通事故')\n",
      "(1467, '着')\n",
      "(1355, '浓烟')\n",
      "(1324, '警察')\n",
      "(1281, '废墟')\n",
      "(1201, '建筑')\n",
      "(1194, '多名')\n",
      "(1193, '散落')\n",
      "(1174, '一名')\n",
      "(1117, '一辆')\n",
      "(1078, '抗议')\n",
      "(1074, '事件')\n",
      "(952, '大火')\n",
      "(915, '了')\n",
      "(902, '飞机')\n",
      "(892, '倒塌')\n",
      "(860, '发生爆炸')\n",
      "(857, '举行')\n",
      "(843, '矿难')\n",
      "(841, '工作')\n",
      "(833, '围观')\n",
      "(770, '街头')\n",
      "(758, '残骸')\n",
      "(738, '受损')\n",
      "(701, '一')\n",
      "(694, '滚滚')\n",
      "(692, '清理')\n",
      "(687, '有')\n",
      "(686, '后')\n",
      "(665, '车祸')\n",
      "(645, '和')\n",
      "(638, '搜救')\n",
      "(634, '海啸')\n",
      "(634, '活动')\n",
      "(632, '工作人员')\n",
      "(630, '损毁')\n",
      "(625, '中')\n",
      "(613, '袭击')\n",
      "(608, '地面')\n",
      "(602, '建筑物')\n",
      "(570, '实施')\n",
      "(562, '浓烟滚滚')\n",
      "(562, '展开')\n",
      "(545, '一片')\n",
      "(540, '道路')\n",
      "(537, '洪水')\n",
      "(528, '一片狼藉')\n",
      "(524, '查看')\n",
      "(521, '公路')\n",
      "(507, '失火')\n",
      "(504, '燃起')\n",
      "(503, '火势')\n",
      "(503, '一地')\n",
      "(501, '空难')\n",
      "(493, '聚集')\n",
      "(492, '从')\n",
      "(487, '男子')\n",
      "(474, '挖掘机')\n",
      "(472, '手持')\n",
      "(467, '抗议者')\n",
      "(459, '出现')\n",
      "(454, '导致')\n",
      "(452, '破损')\n",
      "(432, '正')\n",
      "(430, '造成')\n",
      "(427, '节日')\n",
      "(410, '凶猛')\n",
      "(389, '遭受')\n",
      "(389, '坠毁')\n",
      "(387, '路边')\n",
      "(384, '处理')\n",
      "total words: 265876\n",
      "number of bad words: 2387/6156 = 38.78%\n",
      "number of words in vocab would be 3769\n",
      "number of UNKs: 2387/265876 = 0.90%\n",
      "max length sentence in raw data:  33\n",
      "sentence length distribution (count, number of words):\n",
      " 0:          0   0.000000%\n",
      " 1:          0   0.000000%\n",
      " 2:          4   0.019564%\n",
      " 3:         39   0.190746%\n",
      " 4:          6   0.029346%\n",
      " 5:         24   0.117382%\n",
      " 6:         71   0.347256%\n",
      " 7:        205   1.002641%\n",
      " 8:        588   2.875868%\n",
      " 9:       1415   6.920669%\n",
      "10:       2290   11.200235%\n",
      "11:       2567   12.555023%\n",
      "12:       2600   12.716424%\n",
      "13:       2547   12.457204%\n",
      "14:       2148   10.505722%\n",
      "15:       1879   9.190062%\n",
      "16:       1298   6.348430%\n",
      "17:        942   4.607258%\n",
      "18:        642   3.139978%\n",
      "19:        443   2.166683%\n",
      "20:        304   1.486843%\n",
      "21:        170   0.831458%\n",
      "22:        114   0.557566%\n",
      "23:         55   0.269001%\n",
      "24:         39   0.190746%\n",
      "25:         19   0.092928%\n",
      "26:         14   0.068473%\n",
      "27:          9   0.044018%\n",
      "28:          7   0.034237%\n",
      "29:          4   0.019564%\n",
      "30:          1   0.004891%\n",
      "31:          1   0.004891%\n",
      "32:          0   0.000000%\n",
      "33:          1   0.004891%\n"
     ]
    }
   ],
   "source": [
    "vocab,param = bulid_vocab(data_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
